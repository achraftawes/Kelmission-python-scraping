{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import finish\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re as re\n",
    "import time\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import csv\n",
    "import os\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import schedule\n",
    "from psycopg2.extras import DateTimeRange, DateTimeTZRange\n",
    "\n",
    "print(\"import finish\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script executed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_16204\\3070219728.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=r\"C:\\Chrome\\chromedriver.exe\")\n",
      "Incompatible release of chromedriver (version 109.0.5414.74) detected in PATH: C:\\webdrivers\\chromedriver.exe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1d •', '37m •', '14m •', '35m •', '25m •', '30m •', '39m •', '3w •', '5h •', '1h • Edited •', '44m •', '23h •', '2h • Edited •', '9m •', '9m •', '21m •', '14m •', '12m •', '12m •', '8m •']\n",
      "['2023-07-24 15:44:13', '2023-07-25 15:07:13', '2023-07-25 15:30:13', '2023-07-25 15:09:13', '2023-07-25 15:19:13', '2023-07-25 15:14:13', '2023-07-25 15:05:13', '2023-07-04 15:44:13', '2023-07-25 10:44:13', '2023-07-25 14:44:13', '2023-07-25 15:00:13', '2023-07-24 16:44:13', '2023-07-25 13:44:13', '2023-07-25 15:35:13', '2023-07-25 15:35:13', '2023-07-25 15:23:13', '2023-07-25 15:30:13', '2023-07-25 15:32:13', '2023-07-25 15:32:13', '2023-07-25 15:36:13']\n",
      "['i.koudjonou@montpellier-bs.com', 'recrutement@alsacerhinbrisach.fr', 'recrutement@next-showroom.com', 'recrutement@gem-manutention.com', 'achelidz@yahoo.fr', 'francois.danel@earthwake-entreprise.fr', 'marketing@izyworkci.com', 'agence.cherbourg@lassarat.com', 'matteo@ift-filters.com', 'elodie.allasia@gmail.com', 'pierre.vandeputte@icloud.com', 'recrutement@qualitairsea.com', 'centrehospitalier@ch-stlaurent.com', 'sourcing.alternance@aftral.com', 'sourcing.alternance@aftral.com', 'rh@rouby.fr', 'job@trustafrica-rh.com', 'recrutement@pronal.com', 'recrutement@pronal.com', 'helene.rambaut@nextgenrh.fr']\n",
      "['montpellier-bs', 'alsacerhinbrisach', 'next-showroom', 'gem-manutention', ' ', 'earthwake-entreprise', 'izyworkci', 'lassarat', 'ift-filters', ' ', 'icloud', 'qualitairsea', 'ch-stlaurent', 'aftral', 'aftral', 'rouby', 'trustafrica-rh', 'pronal', 'pronal', 'nextgenrh']\n",
      "Data has been extracted and written to the output files.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def run_script():\n",
    "    driver = webdriver.Chrome(executable_path=r\"C:\\Chrome\\chromedriver.exe\")\n",
    "\n",
    "    url = 'https://www.linkedin.com/login'\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    #import username and password\n",
    "    credential = open('.env')\n",
    "    line = credential.readlines()\n",
    "    username = line[0]\n",
    "    password = line[1]\n",
    "    #key in username\n",
    "    email_field = driver.find_element(By.ID, 'username')\n",
    "    email_field.send_keys(username)\n",
    "    time.sleep(3)\n",
    "    #key in password\n",
    "    password_field = driver.find_element(By.NAME, 'session_password')\n",
    "    password_field.send_keys(password)\n",
    "    time.sleep(2)\n",
    "    #sign in \n",
    "    login_field = driver.find_element(By.XPATH,'//*[@id=\"organic-div\"]/form/div[3]/button')\n",
    "    login_field.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    url = \"https://www.linkedin.com/feed/hashtag/recrutement/\"\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "    initialScroll = 0\n",
    "    finalScroll = 10000\n",
    "    scroll_time = 150 # in seconds\n",
    "\n",
    "    while (time.time() - start) < scroll_time:\n",
    "        driver.execute_script(f\"window.scrollTo({initialScroll},{finalScroll})\")\n",
    "        initialScroll = finalScroll\n",
    "        finalScroll += 10000\n",
    "        time.sleep(3)\n",
    "        \n",
    "        try:\n",
    "            show_more_button = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[3]/div/div/div[2]/div/div/main/div[3]/div/div[2]/div/button')))\n",
    "            show_more_button.click()\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "    infoname = []\n",
    "    job_actor = []\n",
    "    mails = []\n",
    "    date_post = []\n",
    "    description = []\n",
    "    hashtag = []\n",
    "    date_now = [] \n",
    "    ########\n",
    "    page_source = bs(driver.page_source,\"html.parser\")\n",
    "    all_post = page_source.find('div', class_ =\"scaffold-finite-scroll__content\")\n",
    "    postts = all_post.find_all('div',class_ = \"feed-shared-update-v2 feed-shared-update-v2--minimal-padding full-height relative artdeco-card\")\n",
    "\n",
    "    for post in postts:\n",
    "            mailTo = post.find_all('a')\n",
    "            tmp_hashtag = []\n",
    "            for a in mailTo:\n",
    "\n",
    "                if str(a.get('href')).startswith(\"mailto:\") and a.get('href') not in mails: \n",
    "                    mails.append(a.get_text().strip())\n",
    "                    name_info = post.find('span',class_ =\"update-components-actor__name t-14 t-bold hoverable-link-text t-black\")\n",
    "                    infoname.append(name_info.find('span').get_text().strip())    \n",
    "                    job_actor.append(post.find('span',class_=\"update-components-actor__description t-black--light t-12 t-normal\").get_text().strip())\n",
    "                    description.append(post.find('span',class_=\"break-words\").get_text().strip())\n",
    "                    \n",
    "                    date = post.find('div', class_=\"update-components-text-view break-words\")\n",
    "                    if date is not None:\n",
    "                        date_span = date.find('span', class_=\"visually-hidden\")\n",
    "                        if date_span is not None:\n",
    "                            date_post.append(date_span.get_text().strip())\n",
    "                        else:\n",
    "                            pass\n",
    "                    else:\n",
    "                        pass\n",
    "                    \n",
    "                    ###############\n",
    "                    for b in mailTo:\n",
    "                        if str(b.get('href')).startswith(\"https://www.linkedin.com/feed/hashtag/\") and b.get('href') not in tmp_hashtag:\n",
    "                                tmp_hashtag.append(b.get_text().strip())\n",
    "                        else:\n",
    "                            pass\n",
    "                    hashtag.append(tmp_hashtag) \n",
    "                    \n",
    "                    ###############\n",
    "                    \n",
    "                else : \n",
    "                    pass\n",
    "                \n",
    "    \n",
    "    #####################################\n",
    "\n",
    "    prefixes = ['1 minute ago', 'Just', '1 hour ago']\n",
    "    date_ago = []\n",
    "    for k in date_post:\n",
    "        if k.startswith(tuple(prefixes)):\n",
    "            if '1 hour' in k:\n",
    "                date_ago.append('1 hours ago')\n",
    "            else:\n",
    "                date_ago.append('1 minutes ago')\n",
    "        else:\n",
    "            date_ago.append(k) \n",
    "            \n",
    "    print(date_ago) \n",
    "    #### time to timestamp \n",
    "\n",
    "    date_now = []\n",
    "    for datee in date_ago:\n",
    "        # Check if input data matches expected pattern\n",
    "        if re.match(r'\\d+[mhdw] •', datee):\n",
    "            # Split input data by a space\n",
    "            datee_split = datee.split(' ')[0].strip().split()\n",
    "            time_duration = None\n",
    "            try:\n",
    "                time_duration = int(datee_split[0])\n",
    "            except ValueError:\n",
    "                \n",
    "                pass\n",
    "            if time_duration is not None:\n",
    "                dt = datetime.timedelta(minutes=time_duration)\n",
    "            else:\n",
    "                time_unit = datee_split[0][-1]\n",
    "                if time_unit == 'm':\n",
    "                    time_duration = int(datee_split[0][:-1])\n",
    "                    dt = datetime.timedelta(minutes=time_duration)\n",
    "                elif time_unit == 'h':\n",
    "                    time_duration = int(datee_split[0][:-1])\n",
    "                    dt = datetime.timedelta(hours=time_duration)\n",
    "                elif time_unit == 'd':\n",
    "                    time_duration = int(datee_split[0][:-1])\n",
    "                    dt = datetime.timedelta(days=time_duration)\n",
    "                elif time_unit == 'w':  # add support for weeks\n",
    "                    time_duration = int(datee_split[0][:-1])\n",
    "                    dt = datetime.timedelta(weeks=time_duration)\n",
    "                else:\n",
    "                    raise ValueError(f\"Invalid time unit '{time_unit}'. Expected 'm', 'h', 'd', or 'w'.\")\n",
    "            past_time = datetime.datetime.now() - dt\n",
    "            date_now.append(past_time.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        else:\n",
    "            print(f\"Invalid input data: {datee}\")\n",
    "\n",
    "    print(date_now)\n",
    "\n",
    "    print(mails)\n",
    "    #####################################\n",
    "    unwanted_domains = {'gmail', 'yahoo', 'live', 'hotmail', 'outlook'}\n",
    "    domains = []\n",
    "    for email in mails:\n",
    "        domain = email.split('@')[1].split('.')[0]\n",
    "        if domain not in unwanted_domains:\n",
    "            domains.append(domain)\n",
    "        else:\n",
    "            domains.append(' ')\n",
    "    name_societe = domains\n",
    "\n",
    "    print(name_societe)  \n",
    "    #####################################                      \n",
    "    talent = []\n",
    "    #hedhy nhotouha eme menech bech nestaamlouha khater hachetna ken bel loop ahna \n",
    "    for _ in range(len(hashtag)):\n",
    "        talent.append([])\n",
    "\n",
    "    talent_hashtags = []\n",
    "    with open('words_job_talent.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            for tag in line.strip().split(','):\n",
    "                talent_hashtags.append(tag.strip('#'))\n",
    "\n",
    "    for i, hashtags in enumerate(hashtag):\n",
    "        for tag in hashtags:\n",
    "            if tag.strip('#') in talent_hashtags:\n",
    "                talent[i].append(tag.strip('#'))\n",
    "\n",
    "    for i in range(len(talent)):\n",
    "        talent_hashtag_str = ','.join(talent[i])\n",
    "        talent[i] = talent_hashtag_str\n",
    "    #####################################\n",
    "    numero = []\n",
    "    with open('job_descriptions.txt', 'a',encoding=\"utf-8\") as f:\n",
    "        for line in description:\n",
    "            \n",
    "            f.write('\\n')\n",
    "            f.write(line)\n",
    "            f.write('\\n')\n",
    "            phone_regex = r\"\\b(\\d{2}\\s\\d{2}\\s\\d{2}\\s\\d{2}\\s\\d{2}|\\d{3}-\\d{3}-\\d{4}|\\d{2}\\.\\d{2}\\.\\d{2}\\.\\d{2}\\.\\d{2}|\\d{2} \\d{2} \\d{2} \\d{2} \\d{2})\\b\"\n",
    "            matches = re.findall(phone_regex, line)\n",
    "            if len(matches) > 0:\n",
    "                numero.append(matches[0])\n",
    "            else:\n",
    "                numero.append(\"\")\n",
    "            \n",
    "    #####################################    \n",
    "        \n",
    "    df = pd.DataFrame(list(zip(infoname,job_actor,mails,date_now,numero,name_societe,talent,hashtag,description)),\n",
    "        columns =['Nom Actor :', 'His Job :','mail','date','num','company','speciality','Hachtags :','description'])\n",
    "    df.to_csv('scraping.csv',mode='a', index=False, encoding=\"utf-8\",sep=',')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## raja3ha utf-32 juste kaed njarab b utf-8 w badel w bel a \n",
    "\n",
    "\n",
    "    df = pd.read_csv('scraping.csv', encoding=\"utf-8\", sep=',', header=0)\n",
    "    df.drop_duplicates(subset=['Nom Actor :', 'mail'], keep='first', inplace=True)\n",
    "    df = df.iloc[:-1]  # remove last row\n",
    "\n",
    "    # Check if 'Date Post :' column exists\n",
    "    if 'date' in df.columns:\n",
    "        try:\n",
    "            df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "        except ValueError:\n",
    "            # Handle the case when the format doesn't match\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "    df.to_csv('scraping_updated1.csv', mode='w', index=False, encoding=\"utf-8\", sep=',')\n",
    "\n",
    "\n",
    "    input_file = 'scraping_updated1.csv'\n",
    "    category_file = 'category.csv'\n",
    "    job_file = 'job.csv'\n",
    "    company_file = 'company.csv'\n",
    "\n",
    "    # Define the columns to extract from the input file\n",
    "    category_columns = ['speciality']\n",
    "    job_columns = [ 'mail','date','num','company','speciality','description']\n",
    "    company_columns = ['company', 'num']\n",
    "\n",
    "    # Read the input file and extract the desired columns\n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        \n",
    "        category_data = []\n",
    "        job_data = []\n",
    "        company_data = []\n",
    "        \n",
    "        for row in reader:\n",
    "            category_data.append([row[column] for column in category_columns])\n",
    "            job_data.append([row[column] for column in job_columns])\n",
    "            company_data.append([row[column] for column in company_columns])\n",
    "\n",
    "    # Write the extracted data to the output files\n",
    "    with open(category_file, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(category_columns)\n",
    "        writer.writerows(category_data)\n",
    "\n",
    "    with open(job_file, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(job_columns)\n",
    "        writer.writerows(job_data)\n",
    "\n",
    "    with open(company_file, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(company_columns)\n",
    "        writer.writerows(company_data)\n",
    "\n",
    "    print(\"Data has been extracted and written to the output files.\")\n",
    "\n",
    "\n",
    "    # Connect to the PostgreSQL database\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port=5432,\n",
    "        database=\"MyKelMission\",\n",
    "        user=\"postgres\",\n",
    "        password=\"97955187\"\n",
    "    )\n",
    "\n",
    "    # Create a cursor object\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create category table\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS category (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            name VARCHAR(255) NOT NULL\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    # Import category.csv\n",
    "    category_data = pd.read_csv('category.csv')\n",
    "    category_data = category_data[['speciality']]\n",
    "    category_data = category_data.dropna()  # Remove rows with missing values\n",
    "\n",
    "    # Insert category data into the database\n",
    "    for index, row in category_data.iterrows():\n",
    "        cursor.execute(\"INSERT INTO category (name) VALUES (%s)\", (row['speciality'],))\n",
    "\n",
    "    # Create company table\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS company (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            name VARCHAR(255) NOT NULL,\n",
    "            numero VARCHAR(255) NOT NULL,\n",
    "            mail VARCHAR(255)\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    # Import company.csv\n",
    "    company_data = pd.read_csv('company.csv')\n",
    "    company_data = company_data[['company', 'num']]\n",
    "\n",
    "    # Insert company data into the database\n",
    "    for index, row in company_data.iterrows():\n",
    "        cursor.execute(\"INSERT INTO company (name, numero) VALUES (%s, %s)\", (row['company'], row['num']))\n",
    "\n",
    "    # Create job table\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS job (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            mail VARCHAR(255),\n",
    "            date DATE,\n",
    "            num VARCHAR(255),\n",
    "            company_id INTEGER,\n",
    "            speciality VARCHAR(255),\n",
    "            FOREIGN KEY (company_id) REFERENCES company (company_id),\n",
    "            FOREIGN KEY (category_id) REFERENCES category (id),\n",
    "            description VARCHAR(255)\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    # Import job.csv\n",
    "    job_data = pd.read_csv('job.csv')\n",
    "    job_data = job_data[['mail', 'date', 'num', 'company', 'speciality', 'description']]\n",
    "\n",
    "    # Convert 'date' column to pandas DateTime type and handle missing values\n",
    "    job_data['date'] = pd.to_datetime(job_data['date'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "    # Insert job data into the database\n",
    "    for index, row in job_data.iterrows():\n",
    "        # Get the company_id based on the company name\n",
    "        cursor.execute(\"SELECT company_id FROM company WHERE name = %s\", (row['company'],))\n",
    "        company_id = cursor.fetchone()[0]\n",
    "        \n",
    "        # Check if speciality is NaN and handle it appropriately\n",
    "        if pd.isnull(row['speciality']):\n",
    "            category_id = None\n",
    "        else:\n",
    "            # Get the category_id based on the category name\n",
    "            cursor.execute(\"SELECT category_id FROM category WHERE name = %s\", (row['speciality'],))\n",
    "            category_id = cursor.fetchone()[0]\n",
    "        \n",
    "        # Check if date is NaT (Not a Time) and handle it appropriately\n",
    "        if pd.isnull(row['date']):\n",
    "            date_value = None\n",
    "        else:\n",
    "            date_value = row['date']\n",
    "\n",
    "        cursor.execute(\"INSERT INTO job (mail, date, num, company_id, category_id, speciality, description) VALUES (%s, %s, %s, %s, %s, %s, %s)\",\n",
    "                    (row['mail'], date_value, row['num'], company_id, category_id, row['speciality'], row['description']))\n",
    "\n",
    "    # Get the count of emails obtained\n",
    "    mail_count = len(mails)\n",
    "\n",
    "    # Get the current date\n",
    "    current_date = pd.to_datetime('today').date()\n",
    "\n",
    "    # Insert the mail count and current date into the log table\n",
    "    cursor.execute(\"INSERT INTO log (number_jobs, date_log) VALUES (%s, %s)\", (mail_count, current_date))\n",
    "     \n",
    "    \n",
    "    # Commit the changes to the database\n",
    "    conn.commit()\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    \n",
    "print(\"Script executed\")\n",
    "\n",
    "schedule.every().day.at(\"15:40\").do(run_script)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

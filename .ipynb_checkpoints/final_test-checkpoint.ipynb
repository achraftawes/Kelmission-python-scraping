{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T16:08:29.335867Z",
     "iopub.status.busy": "2023-03-21T16:08:29.335867Z",
     "iopub.status.idle": "2023-03-21T16:08:30.332161Z",
     "shell.execute_reply": "2023-03-21T16:08:30.332161Z"
    }
   },
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re as re\n",
    "import time\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import csv\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T16:08:30.332161Z",
     "iopub.status.busy": "2023-03-21T16:08:30.332161Z",
     "iopub.status.idle": "2023-03-21T16:08:41.770278Z",
     "shell.execute_reply": "2023-03-21T16:08:41.770278Z"
    }
   },
   "outputs": [],
   "source": [
    "#driver = webdriver.Chrome(executable_path=r\"C:\\Chrome\\chromedriver.exe\")\n",
    "\n",
    "chromedriver_path = r\"C:\\Chrome\\chromedriver.exe\"\n",
    "service = Service(chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "url = 'https://www.linkedin.com/login'\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T16:08:41.775305Z",
     "iopub.status.busy": "2023-03-21T16:08:41.775305Z",
     "iopub.status.idle": "2023-03-21T16:08:55.538056Z",
     "shell.execute_reply": "2023-03-21T16:08:55.538056Z"
    }
   },
   "outputs": [],
   "source": [
    "#import username and password\n",
    "credential = open ('.env')\n",
    "line = credential.readlines()\n",
    "username = line[0]\n",
    "password = line[1]\n",
    "#key in username\n",
    "email_field = driver.find_element(By.ID, 'username')\n",
    "email_field.send_keys(username)\n",
    "time.sleep(3)\n",
    "#key in password\n",
    "password_field = driver.find_element(By.NAME, 'session_password')\n",
    "password_field.send_keys(password)\n",
    "time.sleep(2)\n",
    "#sign in \n",
    "login_field = driver.find_element(By.XPATH,'//*[@id=\"organic-div\"]/form/div[3]/button')\n",
    "login_field.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T16:08:55.546056Z",
     "iopub.status.busy": "2023-03-21T16:08:55.546056Z",
     "iopub.status.idle": "2023-03-21T16:09:00.535392Z",
     "shell.execute_reply": "2023-03-21T16:09:00.535392Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://www.linkedin.com/feed/hashtag/recrutement/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T16:09:00.543596Z",
     "iopub.status.busy": "2023-03-21T16:09:00.543596Z",
     "iopub.status.idle": "2023-03-21T16:12:21.144736Z",
     "shell.execute_reply": "2023-03-21T16:12:21.144736Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "initialScroll = 0\n",
    "finalScroll = 10000\n",
    "scroll_time = 150 # in seconds\n",
    "\n",
    "while (time.time() - start) < scroll_time:\n",
    "    driver.execute_script(f\"window.scrollTo({initialScroll},{finalScroll})\")\n",
    "    initialScroll = finalScroll\n",
    "    finalScroll += 10000\n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "        show_more_button = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[3]/div/div/div[2]/div/div/main/div[3]/div/div[2]/div/button')))\n",
    "        show_more_button.click()\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T16:12:21.160326Z",
     "iopub.status.busy": "2023-03-21T16:12:21.160326Z",
     "iopub.status.idle": "2023-03-21T16:12:32.449096Z",
     "shell.execute_reply": "2023-03-21T16:12:32.449096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['27m •', '15m • Edited •', '27m •', '26m •', '22m • Edited •', '4m •', '11m • Edited •', '10m •', '3w •', '3h •', '2w •', '5m •', '7m •', '3d •', '1h •', '5d • Edited •', '1w •', '57m •', '2d •', '2w •', '3d •', '4d •', '2w •', '2w •', '4d • Edited •', '7m •', '10m •', '3d • Edited •', '3d •', '2d •', '1mo •', '21m • Edited •', '11m •', '14m •']\n",
      "Invalid input data: 1mo •\n",
      "['2023-05-15 10:31:33', '2023-05-15 10:43:33', '2023-05-15 10:31:33', '2023-05-15 10:32:33', '2023-05-15 10:36:33', '2023-05-15 10:54:33', '2023-05-15 10:47:33', '2023-05-15 10:48:33', '2023-04-24 10:58:33', '2023-05-15 07:58:33', '2023-05-01 10:58:33', '2023-05-15 10:53:33', '2023-05-15 10:51:33', '2023-05-12 10:58:33', '2023-05-15 09:58:33', '2023-05-10 10:58:33', '2023-05-08 10:58:33', '2023-05-15 10:01:33', '2023-05-13 10:58:33', '2023-05-01 10:58:33', '2023-05-12 10:58:33', '2023-05-11 10:58:33', '2023-05-01 10:58:33', '2023-05-01 10:58:33', '2023-05-11 10:58:33', '2023-05-15 10:51:33', '2023-05-15 10:48:33', '2023-05-12 10:58:33', '2023-05-12 10:58:33', '2023-05-13 10:58:33', '2023-05-15 10:37:33', '2023-05-15 10:47:33', '2023-05-15 10:44:33']\n",
      "['m.recrutement2018@gmail.com', 'recrutement@clicjob.dz', 'm.recrutement2018@gmail.com', 'recrutement.lyon@inserm.fr', 'recrutement@clicjob.dz', 'recrutement@whiskylodge.com', 'nessrine.abouhafsa@manpower.fr', 'Samseri91@gmail.com', 'e.jacon@cefimeca.com', 'lvella@hygieneconseils.fr', 'recrutement@qualitairsea.com', 'talents@dnapartners.fr', 'hans.sotobedoya@gmail.com', 'rokhaya.ly@group-optimize.com', 'drh@ejco.com', 'associationzoomjuridique@gmail.com', 'leo.barassin@aphp.fr', 'aubertp1996@outlook.fr', 'sdimeglio@irfasud.fr', 'lilianiribarne@gmail.com', 'recrutement@groupedekkoci.com', 'mission.handicap@mb-expansion.fr', 'rh@champagne-collet.com', 'Peyromauredebordc21@excelia-group.com', 'recrutement@albatros-groupe.com', 'charly.patingre@manpower.fr', 'recrutement@botanicall.fr', 'linael.dangelo@gmail.com', 'recrutement.nim@nexans.com', 'contact@phiavocats.com', 'bastiencognasse@icloud.com', 'abdoelkihel@gmail.com', 'recrutement@cgr-robinetterie.fr', 'geiqlor@wanadoo.fr']\n",
      "[' ', 'clicjob', ' ', 'inserm', 'clicjob', 'whiskylodge', 'manpower', ' ', 'cefimeca', 'hygieneconseils', 'qualitairsea', 'dnapartners', ' ', 'group-optimize', 'ejco', ' ', 'aphp', ' ', 'irfasud', ' ', 'groupedekkoci', 'mb-expansion', 'champagne-collet', 'excelia-group', 'albatros-groupe', 'manpower', 'botanicall', ' ', 'nexans', 'phiavocats', 'icloud', ' ', 'cgr-robinetterie', 'wanadoo']\n"
     ]
    }
   ],
   "source": [
    "infoname = []\n",
    "job_actor = []\n",
    "mails = []\n",
    "date_post = []\n",
    "description_txt = []\n",
    "hashtag = []\n",
    "date_now = [] \n",
    "########\n",
    "page_source = bs(driver.page_source,\"html.parser\")\n",
    "all_post = page_source.find('div', class_ =\"scaffold-finite-scroll__content\")\n",
    "postts = all_post.find_all('div',class_ = \"feed-shared-update-v2 feed-shared-update-v2--minimal-padding full-height relative artdeco-card\")\n",
    "\n",
    "for post in postts:\n",
    "        mailTo = post.find_all('a')\n",
    "        tmp_hashtag = []\n",
    "        for a in mailTo:\n",
    "\n",
    "            if str(a.get('href')).startswith(\"mailto:\") and a.get('href') not in mails: \n",
    "                mails.append(a.get_text().strip())\n",
    "                name_info = post.find('span',class_ =\"update-components-actor__name t-14 t-bold hoverable-link-text t-black\")\n",
    "                infoname.append(name_info.find('span').get_text().strip())    \n",
    "                job_actor.append(post.find('span',class_=\"update-components-actor__description t-black--light t-12 t-normal\").get_text().strip())\n",
    "                description_txt.append(post.find('span',class_=\"break-words\").get_text().strip())\n",
    "                \n",
    "                date = post.find('div', class_=\"update-components-text-view break-words\")\n",
    "                if date is not None:\n",
    "                    date_span = date.find('span', class_=\"visually-hidden\")\n",
    "                    if date_span is not None:\n",
    "                        date_post.append(date_span.get_text().strip())\n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "                ###############\n",
    "                for b in mailTo:\n",
    "                    if str(b.get('href')).startswith(\"https://www.linkedin.com/feed/hashtag/\") and b.get('href') not in tmp_hashtag:\n",
    "                            tmp_hashtag.append(b.get_text().strip())\n",
    "                    else:\n",
    "                        pass\n",
    "                hashtag.append(tmp_hashtag) \n",
    "                \n",
    "                ###############\n",
    "                \n",
    "            else : \n",
    "                pass\n",
    "            \n",
    "  \n",
    "#####################################\n",
    "\n",
    "prefixes = ['1 minute ago', 'Just', '1 hour ago']\n",
    "date_ago = []\n",
    "for k in date_post:\n",
    "    if k.startswith(tuple(prefixes)):\n",
    "        if '1 hour' in k:\n",
    "            date_ago.append('1 hours ago')\n",
    "        else:\n",
    "            date_ago.append('1 minutes ago')\n",
    "    else:\n",
    "        date_ago.append(k) \n",
    "        \n",
    "print(date_ago) \n",
    "#### time to timestamp \n",
    "\n",
    "date_now = []\n",
    "for datee in date_ago:\n",
    "    # Check if input data matches expected pattern\n",
    "    if re.match(r'\\d+[mhdw] •', datee):\n",
    "        # Split input data by a space\n",
    "        datee_split = datee.split(' ')[0].strip().split()\n",
    "        time_duration = None\n",
    "        try:\n",
    "            time_duration = int(datee_split[0])\n",
    "        except ValueError:\n",
    "            pass\n",
    "        if time_duration is not None:\n",
    "            dt = datetime.timedelta(minutes=time_duration)\n",
    "        else:\n",
    "            time_unit = datee_split[0][-1]\n",
    "            if time_unit == 'm':\n",
    "                time_duration = int(datee_split[0][:-1])\n",
    "                dt = datetime.timedelta(minutes=time_duration)\n",
    "            elif time_unit == 'h':\n",
    "                time_duration = int(datee_split[0][:-1])\n",
    "                dt = datetime.timedelta(hours=time_duration)\n",
    "            elif time_unit == 'd':\n",
    "                time_duration = int(datee_split[0][:-1])\n",
    "                dt = datetime.timedelta(days=time_duration)\n",
    "            elif time_unit == 'w':  # add support for weeks\n",
    "                time_duration = int(datee_split[0][:-1])\n",
    "                dt = datetime.timedelta(weeks=time_duration)\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid time unit '{time_unit}'. Expected 'm', 'h', 'd', or 'w'.\")\n",
    "        past_time = datetime.datetime.now() - dt\n",
    "        date_now.append(past_time.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    else:\n",
    "        print(f\"Invalid input data: {datee}\")\n",
    "\n",
    "print(date_now)\n",
    "\n",
    "print(mails)\n",
    "#####################################\n",
    "unwanted_domains = {'gmail', 'yahoo', 'live', 'hotmail', 'outlook'}\n",
    "domains = []\n",
    "for email in mails:\n",
    "    domain = email.split('@')[1].split('.')[0]\n",
    "    if domain not in unwanted_domains:\n",
    "        domains.append(domain)\n",
    "    else:\n",
    "        domains.append(' ')\n",
    "name_societe = domains\n",
    "\n",
    "print(name_societe)  \n",
    "#####################################                      \n",
    "talent = []\n",
    "#hedhy nhotouha eme menech bech nestaamlouha khater hachetna ken bel loop ahna \n",
    "for _ in range(len(hashtag)):\n",
    "    talent.append([])\n",
    "\n",
    "talent_hashtags = []\n",
    "with open('words_job_talent.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        for tag in line.strip().split(','):\n",
    "            talent_hashtags.append(tag.strip('#'))\n",
    "\n",
    "for i, hashtags in enumerate(hashtag):\n",
    "    for tag in hashtags:\n",
    "        if tag.strip('#') in talent_hashtags:\n",
    "            talent[i].append(tag.strip('#'))\n",
    "\n",
    "for i in range(len(talent)):\n",
    "    talent_hashtag_str = ','.join(talent[i])\n",
    "    talent[i] = talent_hashtag_str\n",
    "#####################################\n",
    "numero = []\n",
    "with open('job_descriptions.txt', 'a',encoding=\"utf-8\") as f:\n",
    "    for line in description_txt:\n",
    "        \n",
    "        f.write('______________________________________________________________________')\n",
    "        f.write('\\n')\n",
    "        f.write(line)\n",
    "        f.write('\\n')\n",
    "        phone_regex = r\"\\b(\\d{2}\\s\\d{2}\\s\\d{2}\\s\\d{2}\\s\\d{2}|\\d{3}-\\d{3}-\\d{4}|\\d{2}\\.\\d{2}\\.\\d{2}\\.\\d{2}\\.\\d{2}|\\d{2} \\d{2} \\d{2} \\d{2} \\d{2})\\b\"\n",
    "        matches = re.findall(phone_regex, line)\n",
    "        if len(matches) > 0:\n",
    "            numero.append(matches[0])\n",
    "        else:\n",
    "            numero.append(\"\")\n",
    "        \n",
    "#####################################    \n",
    "    \n",
    "df = pd.DataFrame(list(zip(infoname,job_actor,mails,date_now,numero,name_societe,talent,hashtag)),\n",
    "    columns =['Nom Actor :', 'His Job :','Mail :','Date Post :','Numero :','Entreprise :','Speciality :','Hachtags :'])\n",
    "\n",
    "df.to_csv('scraping.csv',mode='a', index=False, encoding=\"utf-8\",sep=',')\n",
    "\n",
    "\n",
    "## raja3ha utf-32 juste kaed njarab b utf-8 w badel w bel a \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('scraping.csv', encoding=\"utf-8\", sep=',', header=0)\n",
    "df.drop_duplicates(subset=['Nom Actor :', 'Mail :'], keep='first', inplace=True)\n",
    "df = df.iloc[:-1] # remove last row\n",
    "df['Date Post :'] = pd.to_datetime(df['Date Post :']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df.to_csv('scraping_updated1.csv', mode='w', index=False, encoding=\"utf-8\", sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
